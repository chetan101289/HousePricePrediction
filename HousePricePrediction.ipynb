{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "# to show full rows and columns\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "# disable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# display upto 2 decimals\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "\n",
    "# importing libraries for ML algorithm\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv data\n",
    "data = pd.read_csv('train.csv', header='infer', index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shape of DF\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting loaded data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking null values count\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking dtypes and other info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking int & float dtypes and their values\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Univariate Analysis before treating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate the univariate count plots for all the object data types\n",
    "def createplot_count(v1,v2,v3):\n",
    "    gs  = gridspec.GridSpec(4, 1, height_ratios=[1, 1 ,1.5, 1])\n",
    "    plt.subplot2grid((30,3),(v1,v2))\n",
    "    sns.countplot(data[v3])\n",
    "    plt.title(v3, fontsize=18, fontweight='bold')\n",
    "    plt.xticks(rotation=90, fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xlabel('', fontsize=14)\n",
    "    plt.ylabel('Count', fontsize=14)\n",
    "    \n",
    "# function to generate the univariate distribution plots for all the numerical data types\n",
    "def createplot_dist(v1,v2,v3):\n",
    "    gs  = gridspec.GridSpec(4, 1, height_ratios=[1, 1 ,1.5, 1])\n",
    "    plt.subplot2grid((30,2),(v1,v2))\n",
    "    sns.distplot(data[v3], hist=True)\n",
    "    plt.title(v3, fontsize=18, fontweight='bold')\n",
    "    plt.xticks(rotation=90, fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xlabel('', fontsize=14)\n",
    "    plt.ylabel('Density', fontsize=14)\n",
    "    \n",
    "# selecting all the object types features for univariate analysis\n",
    "objlist = data.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Some numerical columns which has a count or rating\n",
    "Xlist = ['OverallQual','OverallCond','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\\\n",
    "        'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars']\n",
    "\n",
    "# selecting all the numerical types features for univariate analysis\n",
    "numlist = data.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "\n",
    "numlist = list(set(numlist)-set(Xlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generating univariate plots for all the object data types\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(20,300))\n",
    "for j in range(21):\n",
    "    for k in range(3):\n",
    "        if i == len(objlist):\n",
    "            break\n",
    "        else:    \n",
    "            createplot_count(j,k, objlist[i])\n",
    "            i+=1\n",
    "            \n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generating univariate plots for the above mentioned data types which i want to keep as numerical as it shows\n",
    "# an order, otherwise i will have to create extra dummies for these features\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(20,250))\n",
    "\n",
    "for j in range(21):\n",
    "    for k in range(3):\n",
    "        if i == len(Xlist):\n",
    "            break\n",
    "        else:    \n",
    "            createplot_count(j,k, Xlist[i])\n",
    "            i+=1\n",
    "            \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generating univariate distribution plots for all the continuous numerical data types\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(20,300))\n",
    "for j in range(21):\n",
    "    for k in range(2):\n",
    "        if i == len(numlist):\n",
    "            break\n",
    "        else:    \n",
    "            createplot_dist(j,k, numlist[i])\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Missing Values Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicates if any\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that needs to converted to object type\n",
    "obj1 = ['MSSubClass','MoSold','YrSold']\n",
    "\n",
    "data[obj1] = data[obj1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alley: Type of alley access to property\n",
    "print(f\"Null Value count: \\n{data['Alley'].isnull().value_counts()}\")\n",
    "\n",
    "# updating null with NA (No alley access)\n",
    "data.loc[data['Alley'].isnull(), ['Alley']] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MasVnrType: Masonry veneer type\n",
    "print(f\"Null Value count: \\n{data['MasVnrType'].isnull().value_counts()}\\n\")\n",
    "print(f\"Mode Value: {data['MasVnrType'].mode()}\")\n",
    "\n",
    "# updating null with mode values \n",
    "data.loc[data['MasVnrType'].isnull(), ['MasVnrType']] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BsmtQual: Evaluates the height of the basement, BsmtCond: Evaluates the general condition of the basement\n",
    "# BsmtExposure: Refers to walkout or garden level walls, BsmtFinType1: Rating of basement finished area\n",
    "# BsmtFinType2: Rating of basement finished area (if multiple types)\n",
    "\n",
    "print(f\"Null Value count: \\n{data['BsmtQual'].isnull().value_counts()}\\n\")\n",
    "print(f\"Null Value count: \\n{data['BsmtCond'].isnull().value_counts()}\\n\")\n",
    "print(f\"Null Value count: \\n{data['BsmtExposure'].isnull().value_counts()}\\n\")\n",
    "print(f\"Null Value count: \\n{data['BsmtFinType1'].isnull().value_counts()}\\n\")\n",
    "print(f\"Null Value count: \\n{data['BsmtFinType2'].isnull().value_counts()}\\n\")\n",
    "\n",
    "# updating missing values with NA as the missing data represents No basement in the property\n",
    "\n",
    "data.loc[data['BsmtQual'].isnull(), ['BsmtQual']] = 'NA'\n",
    "data.loc[data['BsmtCond'].isnull(), ['BsmtCond']] = 'NA'\n",
    "data.loc[data['BsmtExposure'].isnull(), ['BsmtExposure']] = 'NA'\n",
    "data.loc[data['BsmtFinType1'].isnull(), ['BsmtFinType1']] = 'NA'\n",
    "data.loc[data['BsmtFinType2'].isnull(), ['BsmtFinType2']] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electrical: Electrical system\n",
    "\n",
    "print(f\"Null Value count: \\n{data['Electrical'].isnull().value_counts()}\\n\")\n",
    "print(f\"Mode Value: {data['Electrical'].mode()}\")\n",
    "\n",
    "# updating null with mode values \n",
    "data.loc[data['Electrical'].isnull(), ['Electrical']] = 'SBrkr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fireplaces: Number of fireplaces & FireplaceQu: Fireplace quality\n",
    "\n",
    "print(f\"Null Value count: \\n{data['FireplaceQu'].isnull().value_counts()}\\n\")\n",
    "\n",
    "# Almost 47% properties have no fireplaces, so this is the reason that 47% of fireplace quality is null\n",
    "data['Fireplaces'].value_counts(normalize=True)*100\n",
    "\n",
    "# Lets update null values with 'NA' for this feature as it means No fireplace in the property\n",
    "data.loc[data['FireplaceQu'].isnull(), ['FireplaceQu']] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GarageType: Garage location, GarageFinish: Interior finish of the garage, GarageQual: Garage quality\n",
    "# GarageCond: Garage condition\n",
    "\n",
    "print(f\"Null Value count: \\n{data['GarageType'].isnull().value_counts()}\\n\")\n",
    "print(f\"Null Value count: \\n{data['GarageFinish'].isnull().value_counts()}\\n\")\n",
    "print(f\"Null Value count: \\n{data['GarageQual'].isnull().value_counts()}\\n\")\n",
    "print(f\"Null Value count: \\n{data['GarageCond'].isnull().value_counts()}\\n\")\n",
    "\n",
    "# Lets update null values with 'NA' for this feature as it means No garage in the property\n",
    "data.loc[data['GarageType'].isnull(), ['GarageType']] = 'NA'\n",
    "data.loc[data['GarageFinish'].isnull(), ['GarageFinish']] = 'NA'\n",
    "data.loc[data['GarageQual'].isnull(), ['GarageQual']] = 'NA'\n",
    "data.loc[data['GarageCond'].isnull(), ['GarageCond']] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoolQC: Pool quality\n",
    "# PoolArea\n",
    "\n",
    "print(f\"PoolQC Null Value count: \\n{data['PoolQC'].isnull().value_counts(normalize=True)*100}\\n\")\n",
    "\n",
    "# let's update null values with 'NA' which means no pool\n",
    "data.loc[data['PoolQC'].isnull(), ['PoolQC']] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fence: Fence quality\n",
    "# Lets update null values with 'NA' for this feature as it means No fence or Miscellaneous feature in the property\n",
    "\n",
    "print(f\"Null Value count: \\n{data['Fence'].isnull().value_counts()}\\n\")\n",
    "data.loc[data['Fence'].isnull(), ['Fence']] = 'NA'\n",
    "\n",
    "# MiscFeature: Miscellaneous feature not covered in other categories\n",
    "\n",
    "print(f\"Null Value count: \\n{data['MiscFeature'].isnull().value_counts()}\\n\")\n",
    "data.loc[data['MiscFeature'].isnull(), ['MiscFeature']] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GarageYrBlt\n",
    "print(data[['GarageYrBlt','YearBuilt']].corr())\n",
    "\n",
    "# we can see that almost 70% of the Garage year built matches the YearBuilt, it makes sense to impute it for missing values\n",
    "data.loc[data['GarageYrBlt'].isnull(), ['GarageYrBlt']] = data['YearBuilt']\n",
    "data['GarageYrBlt'] = data['GarageYrBlt'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LotFrontage: Linear feet of street connected to property\n",
    "\n",
    "data['LotFrontage'].median()\n",
    "\n",
    "# There are some null values which we need to impute, but its observed that 99% of the null values are \n",
    "# because there is no alley access to those properties// Out of 259, 254 is null where Alley=NA\n",
    "len(data[(data['LotFrontage'].isnull()) & (data['Alley'] =='NA')].index)\n",
    "\n",
    "data.loc[data['LotFrontage'].isnull(), 'LotFrontage'] = 0\n",
    "\n",
    "# checking distribution\n",
    "data['LotFrontage'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MasVnrArea: Masonry veneer area in square feet\n",
    "\n",
    "data[data['MasVnrType']=='None'][['MasVnrArea','MasVnrType']]\n",
    "\n",
    "# Its observed that for MasVnrType 'None' value ,MasVnrArea is 0\n",
    "data.loc[(data['MasVnrArea'].isnull())&(data['MasVnrType']=='None'), 'MasVnrArea'] = 0\n",
    "\n",
    "# checking distribution\n",
    "data['MasVnrArea'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Univariate Analysis after treating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting all the object types features for univariate analysis\n",
    "objlist = data.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Some numerical columns which has a count or rating\n",
    "Xlist = ['OverallQual','OverallCond','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\\\n",
    "        'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars']\n",
    "\n",
    "# selecting all the numerical types features for univariate analysis\n",
    "numlist = data.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "\n",
    "numlist = list(set(numlist)-set(Xlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generating univariate plots for all the object data types\n",
    "i = 0\n",
    "plt.figure(figsize=(20,300))\n",
    "for j in range(21):\n",
    "    for k in range(3):\n",
    "        if i == len(objlist):\n",
    "            break\n",
    "        else:    \n",
    "            createplot_count(j,k, objlist[i])\n",
    "            i+=1\n",
    "            \n",
    "plt.show()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generating univariate plots for the above mentioned data types which i want to keep as numerical as it shows\n",
    "# an order, otherwise i will have to create extra dummies for these features\n",
    "i = 0\n",
    "plt.figure(figsize=(20,250))\n",
    "\n",
    "for j in range(21):\n",
    "    for k in range(3):\n",
    "        if i == len(Xlist):\n",
    "            break\n",
    "        else:    \n",
    "            createplot_count(j,k, Xlist[i])\n",
    "            i+=1\n",
    "            \n",
    "plt.show()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generating univariate distribution plots for all the continuous numerical data types\n",
    "i = 0\n",
    "plt.figure(figsize=(20,300))\n",
    "for j in range(21):\n",
    "    for k in range(2):\n",
    "        if i == len(numlist):\n",
    "            break\n",
    "        else:    \n",
    "            createplot_dist(j,k, numlist[i])\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Bivariate and multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting Bivariate & Multivariate plots\n",
    "plt.figure(figsize=(18,120))\n",
    "\n",
    "plt.subplot2grid((10,2),(0,0))\n",
    "sns.scatterplot(x=data['YearBuilt'], y=data['SalePrice'])\n",
    "plt.title('Year Built vs Price', fontsize=20, fontweight='bold')\n",
    "plt.ylabel('Sale Price', fontsize=14); plt.xlabel('Year Built',fontsize=14)\n",
    "plt.yticks(fontsize=12); plt.xticks(rotation=90,fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(0,1))\n",
    "sns.scatterplot(x=data['TotalBsmtSF'], y=data['SalePrice'], hue=data['BsmtQual'])\n",
    "plt.title('Basement Area(Quality) vs Price', fontsize=20, fontweight='bold')\n",
    "plt.ylabel('Sale Price', fontsize=14); plt.xlabel('Basement Area',fontsize=14)\n",
    "plt.yticks(fontsize=12); plt.xticks(rotation=90,fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(1,0))\n",
    "sns.scatterplot(x=data['LotArea'], y=data['SalePrice'], hue=data['LotShape'])\n",
    "plt.title('Lot Area(Shape) vs Price', fontsize=18, fontweight='bold')\n",
    "plt.ylabel('Sale Price', fontsize=14); plt.xlabel('Lot Area',fontsize=14)\n",
    "plt.yticks(fontsize=12); plt.xticks(rotation=90,fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(1,1))\n",
    "sns.scatterplot(x=data['GrLivArea'], y=data['SalePrice'])\n",
    "plt.title('Ground Living Area vs Price', fontsize=18, fontweight='bold')\n",
    "plt.ylabel('Sale Price', fontsize=14); plt.xlabel('Ground Living Area',fontsize=14)\n",
    "plt.yticks(fontsize=12); plt.xticks(rotation=90,fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(2,0))\n",
    "sns.barplot(x=data['MSSubClass'], y=data['SalePrice'])\n",
    "plt.title('Sub Class vs Price', fontsize=18, fontweight='bold')\n",
    "plt.ylabel('Sale Price', fontsize=14); plt.xlabel('Sub Class',fontsize=14)\n",
    "plt.yticks(fontsize=12); plt.xticks(rotation=90,fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(2,1))\n",
    "sns.barplot(x=data['Neighborhood'], y=data['SalePrice'])\n",
    "plt.title('Neighborhood vs Price', fontsize=18, fontweight='bold')\n",
    "plt.ylabel('Sale Price', fontsize=14); plt.xlabel('Neighborhood',fontsize=14)\n",
    "plt.yticks(fontsize=12); plt.xticks(rotation=90,fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(3,0))\n",
    "sns.boxplot(x=data['YrSold'], y=data['SalePrice'], hue=data['OverallQual'])\n",
    "plt.title('Year Sold(Quality) vs Price', fontsize=20, fontweight='bold')\n",
    "plt.ylabel('Sale Price', fontsize=14); plt.xlabel('Year Sold',fontsize=14)\n",
    "plt.yticks(fontsize=12); plt.xticks(rotation=90,fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(3,1))\n",
    "sns.boxplot(x=data['YrSold'], y=data['SalePrice'], hue=data['OverallCond'])\n",
    "plt.title('Year Sold(Condition) vs Price', fontsize=20, fontweight='bold')\n",
    "plt.ylabel('Sale Price', fontsize=14); plt.xlabel('Year Sold',fontsize=14)\n",
    "plt.yticks(fontsize=12); plt.xticks(rotation=90,fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(4,0))\n",
    "sns.barplot(x=data['HouseStyle'], y=data['SalePrice'], hue=data['BldgType'])\n",
    "plt.title('HouseStyle(Building Type) vs Price', fontsize=18, fontweight='bold')\n",
    "plt.ylabel('Sale Price', fontsize=14); plt.xlabel('HouseStyle',fontsize=14)\n",
    "plt.yticks(fontsize=12); plt.xticks(rotation=90,fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(4,1))\n",
    "sns.boxplot(x=data['Street'], y=data['SalePrice'], hue=data['MSZoning'])\n",
    "plt.title('Zone classification Street vs Price', fontsize=18, fontweight='bold')\n",
    "plt.ylabel('Sale Price', fontsize=14); plt.xlabel('Street',fontsize=14)\n",
    "plt.yticks(fontsize=12); plt.xticks(rotation=90,fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(5,0))\n",
    "sns.barplot(x=data['RoofStyle'], y=data['SalePrice'], hue=data['RoofMatl'])\n",
    "plt.title('Roof Style(Roof Material) vs Price', fontsize=18, fontweight='bold')\n",
    "plt.ylabel('Sale Price', fontsize=14); plt.xlabel('Roof Style',fontsize=14)\n",
    "plt.yticks(fontsize=12); plt.xticks(rotation=90,fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(5,1))\n",
    "sns.boxplot(x=data['GarageType'], y=data['SalePrice'], hue=data['GarageFinish'])\n",
    "plt.title('Garage Type(Garage Finish) vs Price', fontsize=18, fontweight='bold')\n",
    "plt.ylabel('Sale Price', fontsize=14); plt.xlabel('GarageType',fontsize=14)\n",
    "plt.yticks(fontsize=12); plt.xticks(rotation=90,fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(6,0))\n",
    "sns.boxplot(x=data['BsmtCond'], y=data['SalePrice'], hue=data['BsmtExposure'])\n",
    "plt.title('Basement Condition(Basement Exposure) vs Price', fontsize=18, fontweight='bold')\n",
    "plt.ylabel('Sale Price', fontsize=14); plt.xlabel('Basement Condition',fontsize=14)\n",
    "plt.yticks(fontsize=12); plt.xticks(rotation=90,fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(7,0), colspan=2)\n",
    "sns.heatmap(data[numlist].corr(),annot=True, cmap='Blues')\n",
    "plt.title('Correlation Matrix 1', fontsize=18, fontweight='bold')\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.yticks(rotation=0, fontsize=12)\n",
    "\n",
    "plt.subplot2grid((10,2),(8,0), colspan=2)\n",
    "sns.heatmap(data[Xlist].corr(),annot=True, cmap='Blues')\n",
    "plt.title('Correlation Matrix 2', fontsize=18, fontweight='bold')\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.yticks(rotation=0, fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting pairplot\n",
    "data1 = data[['TotalBsmtSF','MasVnrArea','BsmtUnfSF','BsmtFinSF1','BsmtFinSF2','LotFrontage','GarageArea',\\\n",
    "      '1stFlrSF','2ndFlrSF','OpenPorchSF','WoodDeckSF','LotArea','GrLivArea']]\n",
    "\n",
    "sns.pairplot(data1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking top 20 correlation's wrt SalePrice\n",
    "data.corr()['SalePrice'][:20].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "### 3.1 Dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy variables\n",
    "\n",
    "# To reduce the number of dummies we can reduce the very less percentage categories \n",
    "# to a different category 'Others'\n",
    "\n",
    "def create_other(v1):\n",
    "    arr=[]\n",
    "    for k, v in (data[v1].value_counts(normalize=True)*100).to_dict().items():\n",
    "        if v < 2:\n",
    "            arr.append(k)\n",
    "        \n",
    "    data.loc[data[v1].isin(arr), v1] = 'others' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function after analyzing all the features values using valuecount percentages\n",
    "# creating others category only for small percentage categories to reduce dummy variables\n",
    "\n",
    "create_other('MSSubClass')\n",
    "create_other('MSZoning')\n",
    "create_other('Condition1')\n",
    "create_other('Condition2')\n",
    "create_other('RoofStyle')\n",
    "create_other('RoofMatl')\n",
    "create_other('Exterior1st')\n",
    "create_other('Exterior2nd')\n",
    "create_other('ExterCond')\n",
    "create_other('Foundation')\n",
    "create_other('Heating')\n",
    "create_other('Electrical')\n",
    "create_other('Functional')\n",
    "create_other('GarageType')\n",
    "create_other('GarageQual')\n",
    "create_other('GarageCond')\n",
    "create_other('MiscFeature')\n",
    "create_other('SaleType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting all the object types features for dummies creation\n",
    "objlist_dummies = data.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# creating dummy variables\n",
    "dummies_df = pd.get_dummies(data[objlist_dummies])\n",
    "\n",
    "# concatenating dataframes\n",
    "data = pd.concat([data, dummies_df], axis=1)\n",
    "print(data.shape)\n",
    "\n",
    "# dropping categorical value features\n",
    "data = data.drop(objlist_dummies, axis=1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Checking target variable distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting distribution plot for saleprice\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot((data['SalePrice']))\n",
    "plt.show()\n",
    "\n",
    "## As we can see that our target variable is not normally distributed, so we can perform some transformation and\n",
    "# see which transformation can provide us with normally distributed target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting distribution plot for log(saleprice)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.distplot(np.log1p(data['SalePrice']))\n",
    "plt.show()\n",
    "\n",
    "## So, i chose log1p transformation as the saleprice values are very high but other feature values are not\n",
    "# and since log1p works better than log for small values, we are going to use it for transformation and\n",
    "# it has provided us with an almost normally distributed target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's transform the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SalePrice'] = np.log1p(data['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Outlier treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking outliers\n",
    "\n",
    "# selecting all the numerical types features for univariate analysis\n",
    "numlist = data.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "\n",
    "numlist = list(set(numlist)-set(Xlist))\n",
    "\n",
    "data[numlist].describe(percentiles=[.1,.25,.5,.75,.9,.95,.99,.995,.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot boxplot to see the outlier values after checking the outliers from above function\n",
    "\n",
    "out_list=['TotalBsmtSF','MasVnrArea','BsmtFinSF2','BsmtFinSF1','MiscVal','1stFlrSF',\\\n",
    "          'OpenPorchSF','EnclosedPorch','LotArea','3SsnPorch']\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(data[out_list]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treating the outliers and removing features with more than 90% zero values\n",
    "\n",
    "# we can see some significant ouliers in lotArea which can create problem with our log transformation of \n",
    "# independent variables, so its better to cap it at 99 percentile\n",
    "data = data[data['LotArea']<=37567.640]\n",
    "\n",
    "# Since 96% MiscVal data values are 0, its not going to give us anything significant and its better to drop it\n",
    "data['MiscVal'].value_counts(normalize=True)*100\n",
    "data = data.drop('MiscVal', axis=1)\n",
    "\n",
    "# Since 98% 3SsnPorch data values are 0, its not going to give us anything significant and its better to drop it\n",
    "data['3SsnPorch'].value_counts(normalize=True)*100\n",
    "data = data.drop('3SsnPorch', axis=1)\n",
    "\n",
    "# Since 98% LowQualFinSF data values are 0, its not going to give us anything significant and its better to drop it\n",
    "data['LowQualFinSF'].value_counts(normalize=True)*100\n",
    "data = data.drop('LowQualFinSF', axis=1)\n",
    "\n",
    "# Since 92% ScreenPorch data values are 0, its not going to give us anything significant and its better to drop it\n",
    "data['ScreenPorch'].value_counts(normalize=True)*100\n",
    "data = data.drop('ScreenPorch', axis=1)\n",
    "\n",
    "# Since 99.5% values of PoolArea are 0, it's better to drop these features \n",
    "data['PoolArea'].value_counts(normalize=True)*100\n",
    "data = data.drop(['PoolArea'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot boxplot to see the outlier values after checking the outliers from above function\n",
    "\n",
    "out_list=['TotalBsmtSF','MasVnrArea','BsmtFinSF2','BsmtFinSF1','1stFlrSF','OpenPorchSF','EnclosedPorch']\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(data[out_list]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Splitting the data into train and test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into train and test dataframes using sklearn.model_selection.train_test_split method\n",
    "\n",
    "train_df, test_df = train_test_split(data, train_size=0.7, test_size=0.3, random_state=10)\n",
    "\n",
    "# checking shapes after splitting the data\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have fixed some ouliers and all of them seems natural outliers. Let's apply scaling to all the variables including our target variable to which we applied log1p transformation. And if we don't get the desired results, we will transform all the variables with log1p transformation for scaling instead of MinMaxScaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Log transformation to independent variables\n",
    "\n",
    "# getting list of numerical columns for applying transformation\n",
    "numlist1 = data.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "\n",
    "# Initialising the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fitting the scaler and transforming the training data\n",
    "train_df[numlist1] = scaler.fit_transform(train_df[numlist1])\n",
    "\n",
    "# only transforming the test data\n",
    "test_df[numlist1] = scaler.transform(test_df[numlist1])\n",
    "\n",
    "# resetting the index\n",
    "train_df.reset_index(drop=True,inplace=True)\n",
    "test_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# We will use it if we don't get the desired good results from MinMaxScaling by applying log transformation \n",
    "# (we can use np.expm1 to reverse this transformation)\n",
    "# data[numlist1] = data[numlist1].apply(lambda var: np.log1p(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[numlist1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[numlist1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating seperate independent and dependent variable df's\n",
    "\n",
    "# training data\n",
    "y_train = train_df.pop('SalePrice')\n",
    "X_train = train_df\n",
    "\n",
    "# test data\n",
    "y_test = test_df.pop('SalePrice')\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the dependent vriable df\n",
    "\n",
    "y_train = y_train.values.reshape(-1,1)\n",
    "y_test = y_test.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Ridge Regression\n",
    "#### Using RFE to get the important features using estimator=Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using RFE to select features\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# running the RFE, keeping the desired number of features to be half of the actual count of features\n",
    "rfe = RFE(ridge,130)\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating df and extracting the features list\n",
    "\n",
    "rfe_df = pd.DataFrame(list(zip(X_train.columns,rfe.support_,rfe.ranking_)),\n",
    "             columns=('col','rfe support', 'rfe ranking')).sort_values(by='rfe ranking')\n",
    "\n",
    "features_list = rfe_df[rfe_df['rfe support']==True]['col'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Model with and without RFE selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# finding the Ridge hyperparameter- best value of alpha needed for ridge model\n",
    "\n",
    "# alpha values were selected from very low to higher value and after getting the best alpha, some more values \n",
    "# were inserted to make sure we get the best value\n",
    "\n",
    "X_train_ridge_rfe = X_train[features_list]\n",
    "X_test_ridge_rfe = X_test[features_list]\n",
    "\n",
    "folds = [5, 10]\n",
    "param = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1,\n",
    "                   1.2, 1.25, 1.3, 1.35, 1.4, 1.5, 1.55, 1.6, 1.65, 1.7, 1.8, 1.9, 2.0, 2.05, 2.1, 2.15,\n",
    "                   2.2, 3.0, 3.5, 3.75, 4.0, 4.25, 4.5, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000]}\n",
    "\n",
    "model_cv = GridSearchCV(estimator=ridge, param_grid=param, scoring='neg_mean_absolute_error',\n",
    "                       cv=folds[0], return_train_score=True, verbose=1)\n",
    "\n",
    "model_cv_rfe_5 = GridSearchCV(estimator=ridge, param_grid=param, scoring='neg_mean_absolute_error',\n",
    "                       cv=folds[0], return_train_score=True, verbose=1)\n",
    "\n",
    "model_cv_rfe_10 = GridSearchCV(estimator=ridge, param_grid=param, scoring='neg_mean_absolute_error',\n",
    "                       cv=folds[1], return_train_score=True, verbose=1)\n",
    "\n",
    "model_cv.fit(X_train, y_train)\n",
    "model_cv_rfe_5.fit(X_train_ridge_rfe, y_train)\n",
    "model_cv_rfe_10.fit(X_train_ridge_rfe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the best hyperparameter alpha without feature selection\n",
    "print(f'hyperparameter alpha without feature selection: {model_cv.best_params_}')\n",
    "\n",
    "print(f'hyperparameter alpha with RFE feature selection and fold 5: {model_cv_rfe_5.best_params_}')\n",
    "\n",
    "print(f'hyperparameter alpha with RFE feature selection and fold 10: {model_cv_rfe_10.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the ridge model with alpha obtained above and checking the coefficients\n",
    "\n",
    "alpha = model_cv.best_params_['alpha']\n",
    "alpha_ridge_rfe_5 = model_cv_rfe_5.best_params_['alpha']\n",
    "alpha_ridge_rfe_10 = model_cv_rfe_10.best_params_['alpha']\n",
    "\n",
    "ridge = Ridge(alpha=alpha)\n",
    "ridge_rfe_5 = Ridge(alpha=alpha_ridge_rfe_5)\n",
    "ridge_rfe_10 = Ridge(alpha=alpha_ridge_rfe_10)\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_rfe_5.fit(X_train_ridge_rfe, y_train)\n",
    "ridge_rfe_10.fit(X_train_ridge_rfe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients of the models\n",
    "\n",
    "Ridge_coeff = pd.concat([pd.DataFrame(np.reshape(ridge.coef_, (-1,1)), columns=['Ridge']), \n",
    "                         pd.DataFrame(np.reshape(ridge_rfe_5.coef_, (-1,1)), columns=['Ridge_RFE_5']),\n",
    "                         pd.DataFrame(np.reshape(ridge_rfe_10.coef_, (-1,1)), columns=['Ridge_RFE_10'])],\n",
    "         axis=1)\n",
    "\n",
    "Ridge_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions with the above models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on normal Ridge model with 5 folds\n",
    "\n",
    "y_train_pred = ridge.predict(X_train)\n",
    "y_test_pred = ridge.predict(X_test)\n",
    "\n",
    "print(f'Train R2 : {r2_score(y_train, y_train_pred)}')\n",
    "print(f'Test R2 : {r2_score(y_test, y_test_pred)}')\n",
    "print(f'Train Adj R2 : {1-(1-r2_score(y_train, y_train_pred))*(1011-1)/(1011-260-1)}')\n",
    "print(f'Test Adj R2 : {1-(1-r2_score(y_test, y_test_pred))*(434-1)/(434-260-1)}')\n",
    "print(f'Train MeanSqError : {mean_squared_error(y_train, y_train_pred)}')\n",
    "print(f'Test MeanSqError : {mean_squared_error(y_test, y_test_pred)}\\n')\n",
    "\n",
    "# making predictions on RFE feature selected Ridge model with 5 folds\n",
    "\n",
    "y_train_pred_rfe = ridge_rfe_5.predict(X_train_ridge_rfe)\n",
    "y_test_pred_rfe = ridge_rfe_5.predict(X_test_ridge_rfe)\n",
    "\n",
    "print(f'Train Ridge RFE R2_5 : {r2_score(y_train, y_train_pred_rfe)}')\n",
    "print(f'Test Ridge RFE R2_5 : {r2_score(y_test, y_test_pred_rfe)}')\n",
    "print(f'Train Adj R2_5 : {1-(1-r2_score(y_train, y_train_pred_rfe))*(1011-1)/(1011-76-1)}')\n",
    "print(f'Test Adj R2_5 : {1-(1-r2_score(y_test, y_test_pred_rfe))*(434-1)/(434-76-1)}')\n",
    "print(f'Train Ridge RFE R2_5 MeanSqError : {mean_squared_error(y_train, y_train_pred_rfe)}')\n",
    "print(f'Test Ridge RFE R2_5 MeanSqError : {mean_squared_error(y_test, y_test_pred_rfe)}\\n')\n",
    "\n",
    "# making predictions on RFE feature selected Ridge model with 10 folds\n",
    "\n",
    "y_train_pred_rfe_10 = ridge_rfe_10.predict(X_train_ridge_rfe)\n",
    "y_test_pred_rfe_10 = ridge_rfe_10.predict(X_test_ridge_rfe)\n",
    "\n",
    "print(f'Train Ridge RFE R2_10 : {r2_score(y_train, y_train_pred_rfe_10)}')\n",
    "print(f'Test Ridge RFE R2_10 : {r2_score(y_test, y_test_pred_rfe_10)}')\n",
    "print(f'Train Adj R2_10 : {1-(1-r2_score(y_train, y_train_pred_rfe_10))*(1011-1)/(1011-76-1)}')\n",
    "print(f'Test Adj R2_10 : {1-(1-r2_score(y_test, y_test_pred_rfe_10))*(434-1)/(434-76-1)}')\n",
    "print(f'Train Ridge RFE R2_10 MeanSqError : {mean_squared_error(y_train, y_train_pred_rfe_10)}')\n",
    "print(f'Test Ridge RFE R2_10 MeanSqError : {mean_squared_error(y_test, y_test_pred_rfe_10)}\\n')\n",
    "\n",
    "## We can see that the models with selected features are performing much better than the model with all the\n",
    "# features. Let's see next by calculating the VIF's and removing highly correlated features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking VIF values , removing the features with very high values and running the models again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating VIF's to remove the highly correlated features\n",
    "\n",
    "# We are using X_train_ridge_rfe dataframe with 130 features of training data for calculating VIF in this case\n",
    "\n",
    "# Step 1. Run this code to get the VIF values and check it\n",
    "\n",
    "vif_1 = pd.DataFrame()\n",
    "vif_1['features'] = X_train_ridge_rfe.columns\n",
    "vif_1['VIF'] = [variance_inflation_factor(X_train_ridge_rfe.values, i) \n",
    "                 for i in range(X_train_ridge_rfe.shape[1])] # calculating VIF's\n",
    "\n",
    "vif_1.sort_values(by='VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2. Drop the feature with very high value, one by one and then after dropping the feature rerun step 1 \n",
    "# then step 2 until your VIP score reaches below 5 for all the remaining features\n",
    "\n",
    "# I already did this one by one and found the below features to be highly correlated which i will drop now\n",
    "\n",
    "Remove_col_vif = ['BsmtFinSF2','CentralAir_N','SaleCondition_AdjLand','Street_Pave','MSZoning_RM',\n",
    "                  'LandSlope_Gtl','Condition2_Norm','GrLivArea','PoolQC_NA','SaleCondition_Normal',\n",
    "                  'YearBuilt','TotalBsmtSF','GarageYrBlt','SaleType_New','Exterior2nd_CmentBd','OverallQual',\n",
    "                  'SaleType_WD','GarageCars','BedroomAbvGr','Exterior1st_VinylSd','1stFlrSF','CentralAir_Y',\n",
    "                  'FullBath','KitchenQual_Gd','PavedDrive_Y','BsmtQual_Gd','Functional_Typ','GarageCond_TA',\n",
    "                  'TotRmsAbvGrd','MSZoning_RL','OverallCond','HouseStyle_1.5Fin','BldgType_TwnhsE',\n",
    "                    'BsmtExposure_NA','LandContour_Lvl','GarageArea','Condition1_Norm','LotArea','ExterCond_TA',\n",
    "                  'YearRemodAdd','BsmtUnfSF','BsmtFinSF1','Exterior1st_Wd Sdng','Neighborhood_Somerst',\n",
    "                 'HeatingQC_Ex']\n",
    "\n",
    "# dropping all the highly correlated features which we got by running the above code one by one\n",
    "X_train_ridge_rfe = X_train_ridge_rfe.drop(Remove_col_vif, axis=1)\n",
    "X_test_ridge_rfe = X_test_ridge_rfe.drop(Remove_col_vif, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Run this finally to verify it\n",
    "\n",
    "vif_1 = pd.DataFrame()\n",
    "vif_1['features'] = X_train_ridge_rfe.columns\n",
    "vif_1['VIF'] = [variance_inflation_factor(X_train_ridge_rfe.values, i) \n",
    "                 for i in range(X_train_ridge_rfe.shape[1])] # calculating VIF's\n",
    "\n",
    "vif_1.sort_values(by='VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking shape of the df after dropping correlated features\n",
    "print(X_train_ridge_rfe.shape)\n",
    "print(X_test_ridge_rfe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the Grid search model again to get the changed hyperparameter values\n",
    "model_cv_rfe_5.fit(X_train_ridge_rfe, y_train)\n",
    "model_cv_rfe_10.fit(X_train_ridge_rfe, y_train)\n",
    "\n",
    "print(f'hyperparameter alpha with RFE feature selection and fold 5: {model_cv_rfe_5.best_params_}')\n",
    "print(f'hyperparameter alpha with RFE feature selection and fold 10: {model_cv_rfe_10.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the ridge model with alpha obtained above and checking the coefficients\n",
    "\n",
    "alpha_ridge_rfe_5 = model_cv_rfe_5.best_params_['alpha']\n",
    "alpha_ridge_rfe_10 = model_cv_rfe_10.best_params_['alpha']\n",
    "\n",
    "ridge_rfe_5 = Ridge(alpha=alpha_ridge_rfe_5)\n",
    "ridge_rfe_10 = Ridge(alpha=alpha_ridge_rfe_10)\n",
    "\n",
    "ridge_rfe_5.fit(X_train_ridge_rfe, y_train)\n",
    "ridge_rfe_10.fit(X_train_ridge_rfe, y_train)\n",
    "\n",
    "Ridge_coeff_1 = pd.concat([pd.DataFrame(np.reshape(ridge_rfe_5.coef_, (-1,1)), columns=['Ridge_RFE_5']),\n",
    "                         pd.DataFrame(np.reshape(ridge_rfe_10.coef_, (-1,1)), columns=['Ridge_RFE_10'])],\n",
    "         axis=1)\n",
    "\n",
    "Ridge_coeff_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on RFE feature selected Ridge model with 5 folds\n",
    "\n",
    "y_train_pred_rfe_1 = ridge_rfe_5.predict(X_train_ridge_rfe)\n",
    "y_test_pred_rfe_1 = ridge_rfe_5.predict(X_test_ridge_rfe)\n",
    "\n",
    "print(f'Train Ridge RFE R2_5 : {r2_score(y_train, y_train_pred_rfe_1)}')\n",
    "print(f'Test Ridge RFE R2_5 : {r2_score(y_test, y_test_pred_rfe_1)}')\n",
    "print(f'Train Adj R2_5 : {1-(1-r2_score(y_train, y_train_pred_rfe_1))*(1011-1)/(1011-86-1)}')\n",
    "print(f'Test Adj R2_5 : {1-(1-r2_score(y_test, y_test_pred_rfe_1))*(434-1)/(434-86-1)}')\n",
    "print(f'Train Ridge RFE R2_5 MeanSqError : {mean_squared_error(y_train, y_train_pred_rfe_1)}')\n",
    "print(f'Test Ridge RFE R2_5 MeanSqError : {mean_squared_error(y_test, y_test_pred_rfe_1)}\\n')\n",
    "\n",
    "# making predictions on RFE feature selected Ridge model with 10 folds\n",
    "\n",
    "y_train_pred_rfe_10_1 = ridge_rfe_10.predict(X_train_ridge_rfe)\n",
    "y_test_pred_rfe_10_1 = ridge_rfe_10.predict(X_test_ridge_rfe)\n",
    "\n",
    "print(f'Train Ridge RFE R2_10 : {r2_score(y_train, y_train_pred_rfe_10_1)}')\n",
    "print(f'Test Ridge RFE R2_10 : {r2_score(y_test, y_test_pred_rfe_10_1)}')\n",
    "print(f'Train Adj R2_10 : {1-(1-r2_score(y_train, y_train_pred_rfe_10_1))*(1011-1)/(1011-86-1)}')\n",
    "print(f'Test Adj R2_10 : {1-(1-r2_score(y_test, y_test_pred_rfe_10_1))*(434-1)/(434-86-1)}')\n",
    "print(f'Train Ridge RFE R2_10 MeanSqError : {mean_squared_error(y_train, y_train_pred_rfe_10_1)}')\n",
    "print(f'Test Ridge RFE R2_10 MeanSqError : {mean_squared_error(y_test, y_test_pred_rfe_10_1)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we can see that both the above models R2 and Adj R2 are compromised, but with half number of features than before and hence models are much simpler and better than before. So, I tried using it by selecting more features 1st through VIF and then slowly tried reducing but our R2 & adj R2 got reduced by making our model simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data residual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take the first model 'ridge_rfe_5' for further residual analysis\n",
    "\n",
    "res_train = y_train - y_train_pred_rfe_1\n",
    "\n",
    "# 1. error terms distribution plot\n",
    "plt.figure(figsize=(18,18))\n",
    "\n",
    "plt.subplot(221)\n",
    "sns.distplot(res_train, bins = 20)\n",
    "plt.title('Error Terms Distribution', fontsize = 20)            \n",
    "plt.xlabel('Errors', fontsize = 18)  \n",
    "## error terms seems to be normally distributed\n",
    "\n",
    "\n",
    "# 2. look for patterns in residuals plotting a scatter plot\n",
    "plt.subplot(222)\n",
    "plt.scatter(np.arange(len(res_train)), res_train)\n",
    "plt.plot([0]*len(res_train), color='red')\n",
    "plt.title('Residuals Scatter plot', fontsize = 20)\n",
    "## error terms seems to be randomly scattered\n",
    "\n",
    "\n",
    "# 3. plotting qqplot of residuals of Model\n",
    "sm.qqplot(res_train, fit=True, line='s', marker='.' )\n",
    "plt.title('Q-Q plot of Residuals', fontsize=20)\n",
    "\n",
    "# 4. plotting y train and y predicted to see how it fits the pattern\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(y_train, color='black')\n",
    "plt.plot(y_train_pred_rfe_1, color='red')\n",
    "plt.title('Train data Prediction', fontsize=20)\n",
    "## we can see that it catches the patterns perfectly\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the predictions on test data vs actual values\n",
    "\n",
    "res_ridge = y_test - y_test_pred_rfe_1\n",
    "\n",
    "# plotting y test and y predicted to see how it fits the pattern\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(y_test, color='black')\n",
    "plt.plot(y_test_pred_rfe_1, color='red')\n",
    "plt.title('Test data Prediction', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Lasso Regression\n",
    "#### Using RFE to get the important features using estimator=Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using RFE to select features\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# running the RFE, keeping the desired number of features to be half of the actual count of features\n",
    "rfe_l = RFE(lasso,130)\n",
    "rfe_l.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating df and extracting the features list\n",
    "\n",
    "rfe_1asso_df = pd.DataFrame(list(zip(X_train.columns,rfe_l.support_,rfe_l.ranking_)),\n",
    "             columns=('col','rfe support', 'rfe ranking')).sort_values(by='rfe ranking')\n",
    "\n",
    "features_lasso_list = rfe_1asso_df[rfe_1asso_df['rfe support']==True]['col'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Model with and without RFE selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the Lasso hyperparameter- best value of alpha needed for lasso model\n",
    "\n",
    "# alpha values were selected from very low to higher value and after getting the best alpha, some more values \n",
    "# were inserted to make sure we get the best value\n",
    "\n",
    "X_train_lasso_rfe = X_train[features_lasso_list]\n",
    "X_test_lasso_rfe = X_test[features_lasso_list]\n",
    "\n",
    "folds = [5, 10]\n",
    "param = {'alpha': [0.00005, 0.0001, 0.00025, 0.0005, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, \n",
    "                   0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.05, 2.1, 2.15,\n",
    "                   2.2, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000]}\n",
    "\n",
    "model_cv_lasso = GridSearchCV(estimator=lasso, param_grid=param, scoring='neg_mean_absolute_error',\n",
    "                       cv=folds[0], return_train_score=True, verbose=1)\n",
    "\n",
    "model_cv_rfe_lasso_5 = GridSearchCV(estimator=lasso, param_grid=param, scoring='neg_mean_absolute_error',\n",
    "                       cv=folds[0], return_train_score=True, verbose=1)\n",
    "\n",
    "model_cv_rfe_lasso_10 = GridSearchCV(estimator=lasso, param_grid=param, scoring='neg_mean_absolute_error',\n",
    "                       cv=folds[1], return_train_score=True, verbose=1)\n",
    "\n",
    "model_cv_lasso.fit(X_train, y_train)\n",
    "model_cv_rfe_lasso_5.fit(X_train_lasso_rfe, y_train)\n",
    "model_cv_rfe_lasso_10.fit(X_train_lasso_rfe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the best hyperparameter alpha without feature selection\n",
    "print(f'hyperparameter alpha without feature selection: {model_cv_lasso.best_params_}')\n",
    "\n",
    "print(f'hyperparameter alpha with RFE feature selection and fold 5: {model_cv_rfe_lasso_5.best_params_}')\n",
    "\n",
    "print(f'hyperparameter alpha with RFE feature selection and fold 10: {model_cv_rfe_lasso_10.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the ridge model with alpha obtained above and checking the coefficients\n",
    "\n",
    "alpha_lasso = model_cv_lasso.best_params_['alpha']\n",
    "alpha_lasso_rfe_5 = model_cv_rfe_lasso_5.best_params_['alpha']\n",
    "alpha_lasso_rfe_10 = model_cv_rfe_lasso_10.best_params_['alpha']\n",
    "\n",
    "lasso = Lasso(alpha=alpha_lasso)\n",
    "lasso_rfe_5 = Lasso(alpha=alpha_lasso_rfe_5)\n",
    "lasso_rfe_10 = Lasso(alpha=alpha_lasso_rfe_10)\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_rfe_5.fit(X_train_lasso_rfe, y_train)\n",
    "lasso_rfe_10.fit(X_train_lasso_rfe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients of the models\n",
    "\n",
    "Lasso_coeff = pd.concat([pd.DataFrame(np.reshape(lasso.coef_, (-1,1)), columns=['Lasso']), \n",
    "                         pd.DataFrame(np.reshape(lasso_rfe_5.coef_, (-1,1)), columns=['Lasso_RFE_5']),\n",
    "                         pd.DataFrame(np.reshape(lasso_rfe_10.coef_, (-1,1)), columns=['Lasso_RFE_10'])],\n",
    "         axis=1)\n",
    "\n",
    "# we can see many features with '0' value which is what Lasso does\n",
    "#Lasso_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions with above models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on normal Lasso model with 5 folds\n",
    "\n",
    "y_train_pred_lasso = lasso.predict(X_train)\n",
    "y_test_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "print(f'Train R2 : {r2_score(y_train, y_train_pred_lasso)}')\n",
    "print(f'Test R2 : {r2_score(y_test, y_test_pred_lasso)}')\n",
    "print(f'Train Adj R2 : {1-(1-r2_score(y_train, y_train_pred_lasso))*(1011-1)/(1011-260-1)}')\n",
    "print(f'Test Adj R2 : {1-(1-r2_score(y_test, y_test_pred_lasso))*(434-1)/(434-260-1)}')\n",
    "print(f'Train MeanSqError : {mean_squared_error(y_train, y_train_pred_lasso)}')\n",
    "print(f'Test MeanSqError : {mean_squared_error(y_test, y_test_pred_lasso)}\\n')\n",
    "\n",
    "# making predictions on RFE feature selected Lasso model with 5 folds\n",
    "\n",
    "y_train_pred_lasso_rfe = lasso_rfe_5.predict(X_train_lasso_rfe)\n",
    "y_test_pred_lasso_rfe = lasso_rfe_5.predict(X_test_lasso_rfe)\n",
    "\n",
    "print(f'Train Lasso RFE R2_5 : {r2_score(y_train, y_train_pred_lasso_rfe)}')\n",
    "print(f'Test Lasso RFE R2_5 : {r2_score(y_test, y_test_pred_lasso_rfe)}')\n",
    "print(f'Train Lasso Adj R2_5 : {1-(1-r2_score(y_train, y_train_pred_lasso_rfe))*(1011-1)/(1011-130-1)}')\n",
    "print(f'Test Lasso Adj R2_5 : {1-(1-r2_score(y_test, y_test_pred_lasso_rfe))*(434-1)/(434-130-1)}')\n",
    "print(f'Train Lasso RFE R2_5 MeanSqError : {mean_squared_error(y_train, y_train_pred_lasso_rfe)}')\n",
    "print(f'Test Lasso RFE R2_5 MeanSqError : {mean_squared_error(y_test, y_test_pred_lasso_rfe)}\\n')\n",
    "\n",
    "# making predictions on RFE feature selected Lasso model with 10 folds\n",
    "\n",
    "y_train_pred_lasso_rfe_10 = lasso_rfe_10.predict(X_train_lasso_rfe)\n",
    "y_test_pred_lasso_rfe_10 = lasso_rfe_10.predict(X_test_lasso_rfe)\n",
    "\n",
    "print(f'Train Lasso RFE R2_10 : {r2_score(y_train, y_train_pred_lasso_rfe_10)}')\n",
    "print(f'Test Lasso RFE R2_10 : {r2_score(y_test, y_test_pred_lasso_rfe_10)}')\n",
    "print(f'Train Lasso Adj R2_10 : {1-(1-r2_score(y_train, y_train_pred_lasso_rfe_10))*(1011-1)/(1011-130-1)}')\n",
    "print(f'Test Lasso Adj R2_10 : {1-(1-r2_score(y_test, y_test_pred_lasso_rfe_10))*(434-1)/(434-130-1)}')\n",
    "print(f'Train Lasso RFE R2_10 MeanSqError : {mean_squared_error(y_train, y_train_pred_lasso_rfe_10)}')\n",
    "print(f'Test Lasso RFE R2_10 MeanSqError : {mean_squared_error(y_test, y_test_pred_lasso_rfe_10)}\\n')\n",
    "\n",
    "## We can see that the models with selected features are performing worse than the model with all the\n",
    "# features but this model Adjusted R2 and R2 gap is too wide. So, all the models we used here are not upto \n",
    "# the mark. Let's see next by calculating the VIF's for the model with all the features and removing \n",
    "# highly correlated features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since our base  model for Lasso is working much better than the other ones, we will be continuing with that model.\n",
    "#### Checking VIF values , removing the features with very high values and running the models again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating VIF's to remove the highly correlated features\n",
    "\n",
    "# We are using full dataframe with full features of training data for calculating VIF in this case\n",
    "\n",
    "# Step 1. Run this code to get the VIF values and check it\n",
    "\n",
    "vif_lasso = pd.DataFrame()\n",
    "vif_lasso['features'] = X_train.columns\n",
    "vif_lasso['VIF'] = [variance_inflation_factor(X_train.values, i) \n",
    "                 for i in range(X_train.shape[1])] # calculating VIF's\n",
    "\n",
    "# getting the VIF's sorted, easier to check\n",
    "vif_lasso.sort_values(by='VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2. Drop the feature with very high value, one by one and then after dropping the feature rerun step 1 \n",
    "# then step 2 until your VIP score reaches below 5 for all the remaining features\n",
    "\n",
    "# I already did this one by one and found the below features to be highly correlated which i will drop now\n",
    "\n",
    "Remove_lasso_vif = ['Exterior2nd_Wd Shng','SaleCondition_Partial','Exterior1st_BrkFace','MoSold_4','HouseStyle_2Story',\n",
    "                   'RoofStyle_Hip','Fence_MnPrv','PoolQC_Gd','BldgType_Duplex','PavedDrive_Y','BldgType_1Fam',\n",
    "                   'GarageQual_Fa','Condition1_others','GarageType_NA','GarageFinish_NA','GarageFinish_RFn',\n",
    "                   'Neighborhood_SawyerW','Functional_Min2','FireplaceQu_Fa','KitchenQual_Gd','Electrical_SBrkr',\n",
    "                   'BsmtQual_NA','LandSlope_Mod','CentralAir_Y','LotConfig_FR3','HeatingQC_TA','GarageType_Detchd',\n",
    "                   'LandContour_Low','Heating_GasA','LotShape_Reg','BsmtFinType2_NA','Alley_Pave','RoofMatl_CompShg',\n",
    "                   'MSZoning_RM','BsmtFinType1_NA','BsmtFinType1_LwQ','Condition2_others','MSSubClass_80',\n",
    "                   'BsmtQual_Ex','MSSubClass_190','ExterQual_Gd','BsmtCond_NA','GarageCond_TA','ExterCond_Gd',\n",
    "                   'MasVnrType_BrkFace','MiscFeature_Shed','Street_Grvl','YrSold_2010','BsmtExposure_NA',\n",
    "                   'Foundation_PConc','BsmtFinSF2','SaleType_others','GarageCond_NA','Utilities_AllPub','BsmtCond_TA',\n",
    "                   'GrLivArea','PoolQC_NA','Street_Pave','BsmtFinType2_Unf','SaleCondition_Normal','TotalBsmtSF',\n",
    "                   'LotConfig_Inside','YearBuilt','Condition2_Norm','BsmtExposure_No','MSSubClass_20','GarageYrBlt',\n",
    "                   'LandContour_Lvl','HouseStyle_1Story','OverallQual','Alley_NA','Exterior1st_CemntBd',\n",
    "                   'GarageQual_TA','GarageCars','BedroomAbvGr','Exterior2nd_MetalSd','1stFlrSF','SaleType_WD',\n",
    "                   'Exterior1st_VinylSd','Functional_Typ','LandSlope_Gtl','FireplaceQu_NA','FullBath','MiscFeature_NA',\n",
    "                   'MSZoning_RL','OverallCond','Condition1_Norm','TotRmsAbvGrd','MSSubClass_50','Exterior2nd_VinylSd',\n",
    "                   'BldgType_TwnhsE','GarageArea','BsmtQual_TA','2ndFlrSF','LotArea','ExterCond_TA','YearRemodAdd',\n",
    "                   'BsmtFinSF1','Exterior1st_HdBoard','Fence_NA','Fireplaces','ExterQual_TA','BsmtFinType1_Unf',\n",
    "                   'GarageType_Attchd','MasVnrType_None','Neighborhood_Somerst','RoofStyle_Gable','Foundation_CBlock',\n",
    "                   'Exterior2nd_Wd Sdng','LotFrontage','BsmtUnfSF','HeatingQC_Ex']\n",
    "\n",
    "\n",
    "# dropping all the highly correlated features which we got by running the above code one by one\n",
    "X_train_lasso_VIF = X_train.drop(Remove_lasso_vif, axis=1)\n",
    "X_test_lasso_VIF = X_test.drop(Remove_lasso_vif, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Run this finally to verify it\n",
    "\n",
    "vif_lasso = pd.DataFrame()\n",
    "vif_lasso['features'] = X_train_lasso_VIF.columns\n",
    "vif_lasso['VIF'] = [variance_inflation_factor(X_train_lasso_VIF.values, i) \n",
    "                 for i in range(X_train_lasso_VIF.shape[1])] # calculating VIF's\n",
    "\n",
    "# getting the VIF's sorted, easier to check\n",
    "vif_lasso.sort_values(by='VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking shape of the df after dropping correlated features\n",
    "print(X_train_lasso_VIF.shape)\n",
    "print(X_test_lasso_VIF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the Grid search model again to get the changed hyperparameter values\n",
    "model_cv_lasso_vif = GridSearchCV(estimator=lasso, param_grid=param, scoring='neg_mean_absolute_error',\n",
    "                       cv=folds[0], return_train_score=True, verbose=1)\n",
    "\n",
    "model_cv_lasso_vif.fit(X_train_lasso_VIF, y_train)\n",
    "\n",
    "print(f'hyperparameter alpha with RFE feature selection and fold 5: {model_cv_lasso_vif.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the lasso model with alpha obtained above and checking the coefficients\n",
    "\n",
    "alpha_lasso_vif = model_cv_lasso_vif.best_params_['alpha']\n",
    "\n",
    "lasso_vif = Lasso(alpha=alpha_lasso_vif)\n",
    "\n",
    "lasso_vif.fit(X_train_lasso_VIF, y_train)\n",
    "\n",
    "Lasso_coeff_vif = pd.concat([pd.DataFrame(np.reshape(lasso_vif.coef_, (-1,1)), columns=['Lasso_VIF'])],\n",
    "                             axis=1)\n",
    "\n",
    "Lasso_coeff_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code used in question 1 and 3\n",
    "#dropcol= ['PoolQC_Ex', 'MasVnrArea','OpenPorchSF','Neighborhood_NoRidge','HouseStyle_2.5Unf'] \n",
    "#ques_df = X_train_lasso_VIF.drop(dropcol, axis=1)\n",
    "#lasso_vif.fit(ques_df, y_train)\n",
    "#Lasso_coeff_vif_1 = pd.concat([pd.DataFrame(np.reshape(lasso_vif.coef_, (-1,1)), columns=['Lasso_VIF']),\n",
    "#                            pd.DataFrame((X_train_lasso_VIF.columns), columns=['feature name'])],\n",
    "#                            axis=1)\n",
    "#Lasso_coeff_vif_1.sort_values(by='Lasso_VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on Lasso VIF feature selected model with 5 folds\n",
    "\n",
    "y_train_pred_vif = lasso_vif.predict(X_train_lasso_VIF)\n",
    "y_test_pred_vif = lasso_vif.predict(X_test_lasso_VIF)\n",
    "\n",
    "y_train_pred_vif = np.reshape(y_train_pred_vif, (-1,1))\n",
    "y_test_pred_vif = np.reshape(y_test_pred_vif, (-1,1))\n",
    "\n",
    "print(f'Train Lasso VIF R2 : {r2_score(y_train, y_train_pred_vif)}')\n",
    "print(f'Test Lasso VIF R2 : {r2_score(y_test, y_test_pred_vif)}')\n",
    "print(f'Train VIF Adj R2 : {1-(1-r2_score(y_train, y_train_pred_vif))*(1011-1)/(1011-148-1)}')\n",
    "print(f'Test VIF Adj R2 : {1-(1-r2_score(y_test, y_test_pred_vif))*(434-1)/(434-148-1)}')\n",
    "print(f'Train Lasso VIF R2 MeanSqError : {mean_squared_error(y_train, y_train_pred_vif)}')\n",
    "print(f'Test Lasso VIF R2 MeanSqError : {mean_squared_error(y_test, y_test_pred_vif)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After observing all the predictions of model with all the features, features reduced by using RFE and VIF, we can say that the last model is performing better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data residual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take the last model 'lasso_vif' which we developed using VIF for further residual analysis\n",
    "\n",
    "res_lasso_train = y_train - y_train_pred_vif\n",
    "\n",
    "# 1. error terms distribution plot\n",
    "plt.figure(figsize=(18,18))\n",
    "\n",
    "plt.subplot(221)\n",
    "sns.distplot(res_lasso_train, bins = 20)\n",
    "plt.title('Error Terms Distribution', fontsize = 20)            \n",
    "plt.xlabel('Errors', fontsize = 18)  \n",
    "## error terms seems to be normally distributed\n",
    "\n",
    "\n",
    "# 2. look for patterns in residuals plotting a scatter plot\n",
    "plt.subplot(222)\n",
    "plt.scatter(np.arange(len(res_lasso_train)), res_lasso_train)\n",
    "plt.plot([0]*len(res_lasso_train), color='red')\n",
    "plt.title('Residuals Scatter plot', fontsize = 20)\n",
    "## error terms seems to be randomly scattered\n",
    "\n",
    "\n",
    "# 3. plotting qqplot of residuals of Model\n",
    "sm.qqplot(res_lasso_train, fit=True, line='s', marker='.' )\n",
    "plt.title('Q-Q plot of Residuals', fontsize=20)\n",
    "\n",
    "# 4. plotting y train and y predicted to see how it fits the pattern\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(y_train, color='black')\n",
    "plt.plot(y_train_pred_vif, color='red')\n",
    "plt.title('Train data Prediction', fontsize=20)\n",
    "## we can see that it's not catching the patterns perfectly as Ridge models were catching\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions on test data vs actual values\n",
    "\n",
    "# plotting y test and y predicted to see how it fits the pattern\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(y_test, color='black')\n",
    "plt.plot(y_test_pred_vif, color='red')\n",
    "plt.title('Test data Prediction', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's very clear that Ridge models are performing better than Lasso models. We can choose the one where feature selection was done through RFE and that model has high R2 and closer adjusted R2. But if we want high bias model with low variance we can select Ridge model where feature selection was done through RFE AND VIF both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
